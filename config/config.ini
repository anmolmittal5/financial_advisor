[credentials]
auth_token = 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


[qwen_7b_chat]
model_name = Qwen-7B-Chat
model_id = Qwen/Qwen-7B-Chat
task = text-generation
num_gpu = 1
instance_type = ml.g5.2xlarge

[llama_2_7b_chat]
model_name = Llama-2-7b-chat-hf
auth_token = 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
model_id = meta-llama/Llama-2-7b-chat-hf
task = text-generation
max_length = 1000
repetition_penalty = 1.1
do_sample = True
top_k = 10
num_return_sequences = 1

[llama_2_7b_chat_quantized]
model_name = llama_2_7b_chat_quantized
model_id = meta-llama/Llama-2-7b-chat-hf
model_path = models/llama-2-7b-chat.ggmlv3.q2_K.bin
model_config = models/config.json
model_type = llama
max_length = 2000

[llama_2_7b_chat_8bit_quantized]
model_name = llama_2_7b_chat_8bit_quantized
model_path = models/llama-2-7b-chat.ggmlv3.q8.0.bin
n_ctx = 4000
n_batch = 1000
model_type = llama
max_length = 2000

[finance_llama_chat]
model_name = finance_llama_chat
model_id = cxllin/Llama2-7b-Finance
model_type = llama